# -*- coding: utf-8 -*-
"""birlestirilmis-samet-tolga-volkan.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pmZBnNfoU1pfADS7bmFdujFvQ8S9_HR2

# **Veri Görselleştirme**
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from google.colab import files
uploaded = files.upload()

oyuncular = pd.read_csv('nba-players.csv')
oyuncular

#oyuncular veri setinin tüm sütunlarının isimlerinin  gösterir.
oyuncular.columns

#Oyuncuların oynadıkları oyun sayısı ile yaptıkları başarılı saha içi atışların saçılım grafiği.gp 'games played' fgm 'field goals made'
plt.figure(figsize = (12, 10))
plt.xlabel("Oynanmış oyun sayısı", fontsize = 20)
plt.ylabel("Saha golü sayısı(field goal)", fontsize = 20)
plt.scatter(oyuncular["gp"], oyuncular["fgm"], color = "orange")
plt.show()

#her oyuncunun oynadığı toplam dakika sayısı 'gp' yani 'games played' oynanan oyun çarpı 'min' yani dakika üzerinden bulunur
oyuncular['Toplam_dakikalar'] = oyuncular['gp']*oyuncular['min']
oyuncular['Toplam_dakikalar']

plt.figure(figsize = (12, 10))
plt.xlabel("Oynanmış toplam dakika", fontsize = 20)
plt.ylabel("oyun başına puan sayısı", fontsize = 20)
plt.scatter(oyuncular['Toplam_dakikalar'],oyuncular["pts"], color = "red")
plt.show()

plt.figure(figsize = (10, 10))
boyutlu = plt.axes(projection='3d')
boyutlu.scatter3D(oyuncular['Toplam_dakikalar'],oyuncular["pts"],oyuncular["3p_made"])
boyutlu.set_xlabel('oynanmış toplam dakikalar')
boyutlu.set_ylabel('toplam basket')
boyutlu.set_zlabel('başarılı üçlük sayısı')

sns.set(rc={'figure.figsize':(11.7,8.27)})
sns.boxplot(data=(oyuncular["3pa"],oyuncular["ftm"],oyuncular["fta"],oyuncular["dreb"],oyuncular["reb"],oyuncular["ast"],oyuncular["tov"]))
#3 point attempts-Free Throw made-Free Throw Attempts-Defensive Rebounds-Rebounds-Assists-Turnovers

#Oyuncuların defansif ribaund sayılarına karşılık yaptıkları bloklar.
sns.jointplot(x = oyuncular["blk"], y =oyuncular["dreb"],height=10,kind='reg',ratio=2 )
plt.show()

#Saha atışlarını kırktan küçük olanlar,kırk ile altmış arasında olanlar ve altmıştan büyük olanlar olarak ayırır
field_goal = {}
field_goal['>= 60'] = len([k for k in oyuncular.fg if k >= 60])
field_goal['40-60'] = len([k for k in oyuncular.fg if (40 <= k) and (k < 60)])
field_goal['<40'] = len([k for k in oyuncular.fg if k < 40])

field_goal.keys()

# Saha atış başarı yüzdesi 40 ile 50 arasında olan oyuncuların başarı yüzdeleri değerince gruplanıp büyüten küçüğe sıralanmış tablosu. 
field_goal_df = oyuncular.fg.value_counts().reset_index()
field_goal_df.columns = ['field_goal', 'count']
field_goal_df[(field_goal_df.field_goal > 40) & (field_goal_df.field_goal < 50)]

plt.style.use('seaborn-white')
plt.figure(figsize = (15, 8))
ax1 = plt.axes()
ax2 = plt.axes([0.65, 0.5, 0.2, 0.3])

bins = range(20 ,100,5)
ax1.hist(x = field_goal_df.field_goal, bins = bins, alpha = 0.5, ec = 'black')

ax2.pie(x = list(field_goal.values()), labels = list(field_goal.keys()),
       shadow = True, explode = (0.2, 0.15, 0.2),
       radius = 1.5)

ax1.set_title('2020 de NBA oyuncularının saha atışı başarılarının yüzdelik dağılımı', fontsize = 18)
ax1.set_xlabel('Saha golü yüzdesi', fontsize = 15)
ax1.set_ylabel('Aralıklar', fontsize = 15)
plt.show()
#2020 yılında NBA oyuncularının saha atış denemelerinin başarı yüzdesinin dağılım grafiği

#Her oyuncunun üçlük atış denemelerinin başarı yüzdelerinin gruplanmış olarak büyükten küçüğe sıralanışı
oyuncular[['3p']]
three_p =oyuncular['3p'].value_counts().reset_index()
three_p.columns = ['3points', 'counts']
three_p

plt.style.use('fivethirtyeight')
fig3, ax3 = plt.subplots(figsize = (15, 8))

ax3.hist(x = three_p['3points'],
         bins = range(0, 100, 10),
         color = 'red',
         ec = 'black')
ax3.set_title('NBA oyuncularının üçlük başarı yüzdeleri')
ax3.set_xlabel('Üçlük başarı oranı (%)')

plt.show()
#Üçlük atmada çoğu kişi yüzde 30 ila 40 arasında bir başarı oranına sahip.Bunlar 100 kişiden biraz daha az
#Bunu 20-30 grubu yaklaşık 80 oyuncu ile takip ediyor 
#10-20 ve 40-50 başarı oranı grupları aynı olan 35 kişi sayısına sahip
#%50'den daha iyi üçlük başarısı oranı olanlar ise sayıca on kişinin altında çok küçük bir grup

#oyuncuların top çalma skorlarını sıralar
steals = oyuncular['stl'].value_counts().reset_index()
steals.columns = ['steal', 'counts']
steals = steals.sort_values('steal')
steals

#oyuncuların asist skorlarını sıralar
assist = oyuncular['ast'].value_counts().reset_index()
assist.columns = ['assist', 'counts']
assist = assist.sort_values('assist')
assist

#oyuncuların blok skorlarını sıralar
block = oyuncular['blk'].value_counts().reset_index()
block.columns = ['block', 'counts']
block = block.sort_values('block')
block

#oyuncuların defansif ribaount skorlarını sıralar
deffensive_reb = oyuncular['dreb'].value_counts().reset_index()
deffensive_reb.columns = ['dreb', 'counts']
deffensive_reb = deffensive_reb.sort_values('dreb')

fig4, ax4 = plt.subplots(figsize = (15, 8))
ax4.plot(block.block, block.counts, color = 'orange', label = 'Blok')
ax4.plot(deffensive_reb.dreb, deffensive_reb.counts, color = 'blue', label = 'Defansif Ribaund')
ax4.plot(assist.assist, assist.counts, color = 'cyan', label = 'Asist')
ax4.plot(steals.steal, steals.counts, color = 'red', label = 'Top Çalma')

ax4.set_title('NBA oyuncularının yetenek ölçümü')
ax4.legend()
ax4.set_xlabel('Eylem yetenek Puanları')
ax4.set_ylabel('Oyuncu sayısı')

plt.show()

#Serbest atışları kırktan küçük olanlar,kırk ile altmış arasında olanlar, altmış ile seksen arasında olanlar ve seksenden büyük olanlar olarak ayırır
free_throw = {}
free_throw['>= 80'] = len([k for k in oyuncular.ft if k >= 80])
free_throw['60-80'] = len([k for k in oyuncular.ft if (k>=60) & (k < 80)])
free_throw['40-60'] = len([k for k in oyuncular.ft if (k>=40) & (k<60)])
free_throw['<40'] = len([k for k in oyuncular.ft if (k<40)])

free_throw

plt.style.use('seaborn-white')
plt.figure(figsize = (15, 8))
ax5 = plt.axes()
ax6 = plt.axes([0.2, 0.5, 0.2, 0.3])

colors = ['#66FFFF', '#FFFF33', '#FF7733', '#FF00FF']

ax5.hist(x = oyuncular.ft,
         bins = range(0, 110, 10), ec = 'black')
ax5.set_xlabel('Yüzde (%)')
ax5.set_title('NBA oyuncularının başarılı serbest atış oranları')


ax6.pie(list(free_throw.values()),
        labels = list(free_throw.keys()),
        colors = colors,
        explode = (0.15, 0, 0.15, 0.2),
        radius = 1.5, shadow = True)

plt.show()

toplam_dakikalar = oyuncular.Toplam_dakikalar
toplam_dakikalar.describe()

def get_average_target(a, b):
    df = oyuncular[(oyuncular.Toplam_dakikalar >= a) & (oyuncular.Toplam_dakikalar < b)]
    return round(np.mean(df.target_5yrs), 2)

get_average_target(0,500)
#2020 yılında 0 ile 500 dakika arasında oyunda kalmış oyuncuların gelecek beş yıl içinde ligde kalma ihtimali başarı oranı

fig6, ax6 = plt.subplots(figsize = (15, 8))
bins = range(0, 4000, 500)
x = range(250, 3500, 500)
y = [get_average_target(bins[i], bins[i+1]) for i in range(len(bins)-1)]
ax6.hist(toplam_dakikalar,
         bins = bins,
         alpha = 0.8,
         ec = 'black')

ax6_ = ax6.twinx()
ax6_.plot(x, y, 'r-o')

ax6.set_xlabel('NBA oyuncularının toplam oyun süreleri')
ax6.set_title('Toplam oyun süresi ile uzun kariyer arsındaki bağıntı')

ax6.set_ylabel('Değerler', color = 'blue')
ax6_.set_ylabel('Oran (/1)', color = 'red')

ax6.tick_params(axis = 'y', colors = 'blue')
ax6_.tick_params(axis = 'y', colors = 'red')

"""# **Veri setinin öğrenmeye uygun hale getirilmesi**"""

uploaded = files.upload()

df = pd.read_csv('nba-players-son.csv')
df

df.info()

beşyıl_ligde=df[df['target_5yrs']==1]
beşyıl_değil=df[df['target_5yrs']==0]
print(beşyıl_ligde.shape,beşyıl_değil.shape,df.shape)

from sklearn.preprocessing import MinMaxScaler
x1 = df.drop("target_5yrs", axis=1,)
x1.drop(["Unnamed: 0","name"], inplace=True, axis=1)
#x.drop('name',inplace=True,axis=1)
y = df['target_5yrs']
scaler=MinMaxScaler()
x=scaler.fit_transform(x1)
print(x)
#Veri setinden gereksiz olan sıra ve isim bilgisi içeren kolon çıkarıldı.

from imblearn.under_sampling import RandomUnderSampler

rus=RandomUnderSampler(random_state=0)
rusx_df,rusy_df=rus.fit_resample(x,y)
print(rusx_df.shape,rusy_df.shape)

print(rusx_df)

from sklearn.model_selection import train_test_split
from collections import Counter

#Rastgele aşağı örnekleme veri seti test ve eğitim olarak ayrıldı
rusx_train, rusx_test, rusy_train, rusy_test = train_test_split(rusx_df, rusy_df, test_size=0.2, random_state=6)
print(f"Training target statistics: {Counter(rusy_train)}")
print(f"Testing target statistics: {Counter(rusy_test)}")
print(rusx_train.shape,rusx_test.shape,rusy_train.shape,rusy_test.shape)

print(rusx_train)

#dengesiz veri test ve eğitim olarak ayırma işlemi
densizx_train, densizx_test, densizy_train, densizy_test = train_test_split(x, y, test_size=0.2, random_state=0)
print(f"Training target statistics: {Counter(densizy_train)}")
print(f"Testing target statistics: {Counter(densizy_test)}")
print(densizx_train.shape,densizx_test.shape,densizy_train.shape,densizy_test.shape)
# 1 ve 0 oranları bozulmadan bir bölme işlemi sağlandı

from imblearn.over_sampling import SMOTE
smote = SMOTE(random_state=4)
smox_df,smoy_df=smote.fit_resample(x,y)
#print(f"Training target statistics: {Counter(smox_df)}")
print(f"Testing target statistics: {Counter(smoy_df)}")
print(smox_df.shape,smoy_df.shape)

smox_train, smox_test, smoy_train, smoy_test = train_test_split(smox_df,smoy_df, test_size=0.2, random_state=5)
print(f"Training target statistics: {Counter(smoy_train)}")
print(f"Testing target statistics: {Counter(smoy_test)}")
print(smox_train.shape,smox_test.shape,smoy_train.shape,smoy_test.shape)

"""#**LogisticRegression**"""

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix, classification_report,f1_score,recall_score,roc_auc_score, roc_curve
from sklearn.model_selection import GridSearchCV

grid={"C":np.logspace(0, 4, 10) , "penalty":["l1","l2"],"solver":["liblinear","lbfgs","newton-cg","sag","saga"]}
#[0.001,0.005, 0.01,0.05,0.075,0.080, 0.1,0.5, 1,5, 10,50, 100,500, 1000]
model1 = LogisticRegression(random_state=0, max_iter=20000)
model_1=GridSearchCV(model1,grid)
model_1.fit(rusx_train,rusy_train)
log_reg_pred = model_1.predict(rusx_test)
#train_acc = accuracy_score(rusx_train, rusy_train)
accuracy = accuracy_score(rusy_test,log_reg_pred,normalize = True)
acc11 = model_1.score(rusx_test,rusy_test)
acc21 = model_1.score(rusx_train,rusy_train)
print("Accuracy: %.3f"%(accuracy))
#print("train acc: %.3f"%(trainacc))
print(classification_report(rusy_test, log_reg_pred))
print(acc11)
print(acc21)
print(accuracy)
print(model_1.best_params_)
print(confusion_matrix(rusy_test,log_reg_pred))

grid2={"C":np.logspace(0, 4, 10) , "penalty":["l1","l2"],"solver":["liblinear","lbfgs","newton-cg","sag","saga"]}
#[0.001,0.005, 0.01,0.05,0.075,0.080, 0.1,0.5, 1,5, 10,50, 100,500, 1000]
model12 = LogisticRegression(random_state=8, max_iter=20000)
model_12=GridSearchCV(model12,grid2)
model_12.fit(smox_train,smoy_train)
log_reg_pred12 = model_12.predict(smox_test)
#train_acc = accuracy_score(rusx_train, rusy_train)
accuracy = accuracy_score(smoy_test,log_reg_pred12,normalize = True)
acc1 = model_12.score(smox_test,smoy_test)
acc2 = model_12.score(smox_train,smoy_train)
print("Accuracy: %.3f"%(accuracy))
#print("train acc: %.3f"%(trainacc))
print(classification_report(smoy_test, log_reg_pred12))
print(acc1)
print(acc2)
print(model_12.best_params_)
print(confusion_matrix(smoy_test,log_reg_pred12))

grid2={"C":np.logspace(0, 4, 10) , "penalty":["l1","l2"],"solver":["liblinear","lbfgs","newton-cg","sag","saga"]}
#[0.001,0.005, 0.01,0.05,0.075,0.080, 0.1,0.5, 1,5, 10,50, 100,500, 1000]
model13 = LogisticRegression(random_state=8, max_iter=20000)
model_13=GridSearchCV(model13,grid2)
model_13.fit(densizx_train,densizy_train)
log_reg_pred13 = model_13.predict(densizx_test)
#train_acc = accuracy_score(rusx_train, rusy_train)
accuracy3 = accuracy_score(densizy_test,log_reg_pred13,normalize = True)
acc13 = model_13.score(densizx_test,densizy_test)
acc23 = model_13.score(densizx_train,densizy_train)
print("Accuracy: %.3f"%(accuracy3))
#print("train acc: %.3f"%(trainacc))
print(classification_report(densizy_test, log_reg_pred13))
print(acc13)
print(acc23)
print(model_13.best_params_)
print(confusion_matrix(densizy_test,log_reg_pred13))

"""# **Gaussian NB**"""

from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix, classification_report,f1_score,recall_score,roc_auc_score, roc_curve
from sklearn.model_selection import GridSearchCV

grid3={'var_smoothing': np.logspace(0,-9, num=100)}
model2=GaussianNB ()
model_2=GridSearchCV(model2,grid3)
model_2.fit(rusx_train,rusy_train)
gaus_nb_pred2 = model_2.predict(rusx_test)
accuracy2= accuracy_score(rusy_test,gaus_nb_pred2,normalize = True)
acc =model_2.score(rusx_test,rusy_test)
acc_train=model_2.score(rusx_train,rusy_train)
print(model_2.best_params_)
print(classification_report(rusy_test,gaus_nb_pred2))
print("Test Accuracy: %.5f"%(accuracy2))
print("Train Accuracy: %.5f"%(acc_train))
print(confusion_matrix(rusy_test,gaus_nb_pred2))

grid31={'var_smoothing': np.logspace(0,-9, num=100)}
model21=GaussianNB ()
model_21=GridSearchCV(model21,grid31)
model_21.fit(smox_train,smoy_train)
gaus_nb_pred21 = model_21.predict(smox_test)
accuracy21= accuracy_score(smoy_test,gaus_nb_pred21,normalize = True)
acc21 =model_21.score(smox_test,smoy_test)
acc_train21=model_21.score(smox_train,smoy_train)
print(model_21.best_params_)
print(classification_report(smoy_test,gaus_nb_pred21))
print("Test Accuracy: %.5f"%(accuracy21))
print("Train Accuracy: %.5f"%(acc_train21))
print(confusion_matrix(smoy_test,gaus_nb_pred21))

grid32={'var_smoothing': np.logspace(0,-9, num=100)}
model22=GaussianNB ()
model_22=GridSearchCV(model22,grid32)
model_22.fit(densizx_train,densizy_train)
gaus_nb_pred22 = model_22.predict(densizx_test)
accuracy22= accuracy_score(densizy_test,gaus_nb_pred22,normalize = True)
acc21 =model_22.score(densizx_test,densizy_test)
acc_train22=model_22.score(densizx_train,densizy_train)
print(model_22.best_params_)
print(classification_report(densizy_test,gaus_nb_pred22))
print("Test Accuracy: %.5f"%(accuracy22))
print("Train Accuracy: %.5f"%(acc_train22))
print(confusion_matrix(densizy_test,gaus_nb_pred22))

"""# **Bernolli NB**"""

from sklearn.naive_bayes import BernoulliNB
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix, classification_report,f1_score,recall_score,roc_auc_score, roc_curve
from sklearn.model_selection import GridSearchCV

gridB={'alpha': [0.01, 0.1, 0.5, 1.0, 10.0,20.0,50.0,100.0],'fit_prior' :[True,False]}
model3=BernoulliNB()
model_3=GridSearchCV(model3,gridB)
model_3.fit(rusx_train,rusy_train)
bernou_nb_pred3=model_3.predict(rusx_test)
accuracy3=accuracy_score(rusy_test,bernou_nb_pred3,normalize=True)
acc3=model_3.score(rusx_test,rusy_test)
acctrain3=model_3.score(rusx_train,rusy_train)
print(model_3.best_params_)
print(classification_report(rusy_test,bernou_nb_pred3))
print("Test Accuracy: %.5f"%(accuracy3))
print("Train Accuracy: %.5f"%(acctrain3))
print(confusion_matrix(rusy_test,bernou_nb_pred3))

grid4={'alpha': [0.01, 0.1, 0.5, 1.0, 10.0,20.0,50.0,100.0],'fit_prior' :[True,False]}
model31=BernoulliNB()
model_31=GridSearchCV(model31,grid4)
model_31.fit(smox_train,smoy_train)
bernou_nb_pred31=model_31.predict(smox_test)
accuracy31=accuracy_score(smoy_test,bernou_nb_pred31,normalize=True)
acc3=model_31.score(smox_test,smoy_test)
acctrain31=model_31.score(smox_train,smoy_train)
print(model_31.best_params_)
print(classification_report(smoy_test,bernou_nb_pred31))
print("Test Accuracy: %.5f"%(accuracy31))
print("Train Accuracy: %.5f"%(acctrain31))
print(confusion_matrix(smoy_test,bernou_nb_pred31))

grid5={'alpha': [0.01, 0.1, 0.5, 1.0, 10.0,20.0,50.0,100.0],'fit_prior' :[True,False]}
model32=BernoulliNB()
model_32=GridSearchCV(model32,grid5)
model_32.fit(densizx_train,densizy_train)
bernou_nb_pred32=model_32.predict(densizx_test)
accuracy32=accuracy_score(densizy_test,bernou_nb_pred32,normalize=True)
acc32=model_32.score(densizx_test,densizy_test)
acctrain32=model_32.score(densizx_train,densizy_train)
print(model_32.best_params_)
print(classification_report(densizy_test,bernou_nb_pred32))
print("Test Accuracy: %.5f"%(accuracy32))
print("Train Accuracy: %.5f"%(acctrain32))
print(confusion_matrix(densizy_test,bernou_nb_pred32))

"""# **Gradient Boosting**

**Modelin tanımlanması:**
"""

from sklearn.ensemble import GradientBoostingClassifier
gb = GradientBoostingClassifier()

from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix

def ml_alg(X_train, y_train, X_test, y_test, ml, gS):
  ml.fit(X_train,y_train)
  y_pred = ml.predict(X_test)
  acc_test_train = np.array([ml.score(X_test,y_test),ml.score(X_train,y_train)])
  print("Karışıklık matrisi:\n",confusion_matrix(y_test, y_pred))
  print("\nSınıflandırma raporu:\n",classification_report(y_test, y_pred))
  if(gS == 1):
    print("En iyi parametreler: %s\n" %ml.best_params_)
  return acc_test_train

"""**Dengesiz veri seti ile eğitilmesi ve sonuçlar:**"""

unb =  ml_alg(densizx_train, densizy_train, densizx_test, densizy_test, gb, 0)
#unb =  ml_alg(X_train, y_train, X_test, y_test, gb, 0)
print("Dengesiz test kümesinin başarı oranı: ",unb[0])
print("Dengesiz train kümesinin başarı oranı: ",unb[1])

"""**Random Unsampling uygulanmış veri seti ile eğitim ve test:**"""

ru = ml_alg(rusx_train, rusy_train, rusx_test, rusy_test, gb, 0)
#ru = ml_alg(Xr_train, yr_train, Xr_test, yr_test, gb, 0)

print("Dengeli(Random Unsampling) test kümesinin başarı oranı: ",ru[0])
print("Dengeli(Random Unsampling) train kümesinin başarı oranı: ",ru[1])

"""**SMOTE uygulanmış veri seti ile eğitim ve test:**"""

smt = ml_alg(smox_train, smoy_train, smox_test, smoy_test, gb, 0)
#smt = ml_alg(Xs_train, ys_train, Xs_test, ys_test, gb, 0)

print("Dengeli(SMOTE) test kümesinin başarı oranı: ",smt[0])
print("Dengeli(SMOTE) train kümesinin başarı oranı: ",smt[1])

"""**En uygun hiperparametrelerin bulunması:**

"""

from sklearn.model_selection import GridSearchCV

param_grid = {
    'max_depth': [3, 7, 9],
    'subsample': [0.5, 0.7, 1.0],
    'n_estimators': [50, 100, 500],
    'learning_rate': [0.001, 0.01, 0.1],
    'min_samples_split':[2 , 5, 10], 
}
grid_search = GridSearchCV(GradientBoostingClassifier(), param_grid = param_grid, n_jobs = -1, verbose=2, cv=2)

"""**Dengesiz veri seti ile grid search uygulanmış model sonuçları:**"""

unb_H = ml_alg(densizx_train, densizy_train, densizx_test, densizy_test, grid_search, 1)
print("Dengesiz test kümesi ile grid search uygulanmış modelin başarı oranı: ",unb_H[0])
print("Dengesiz train kümesi ile grid search uygulanmış modelin başarı oranı: ",unb_H[1])

"""**Random Undersampling veri seti ile grid search uygulanmış model sonuçları:**"""

ru_H = ml_alg(rusx_train, rusy_train, rusx_test, rusy_test, grid_search, 1)
print("Dengeli(Random Unsampling) test kümesi ile grid search uygulanmış modelin başarı oranı: ",ru_H[0])
print("Dengeli(Random Unsampling) train kümesi ile grid search uygulanmış modelin başarı oranı: ",ru_H[1])

"""**Smote veri seti ile grid search uygulanmış model sonuçları:**"""

smt_H = ml_alg(smox_train, smoy_train, smox_test, smoy_test, grid_search, 1)

print("Dengeli(SMOTE) test kümesi ile grid search uygulanmış modelin başarı oranı: ",smt_H[0])
print("Dengeli(SMOTE) train kümesi ile grid search uygulanmış modelin başarı oranı: ",smt_H[1])

"""**Başarı oranları tablo:**"""

def acc_table(unb,unb_H,ru,ru_H,smt,smt_H):
  acc_table= np.array([[unb[0], unb[1], unb_H[0], unb_H[1]], 
                     [ru[0], ru[1], ru_H[0], ru_H[1]], 
                     [smt[0], smt[1], smt_H[0], smt_H[1]]])

  index = np.array(['Dengesiz veri seti','Random Unsampling Uygulanmış veri seti','SMOTE Uygulanmış veri seti'])
  columns = np.array(['test_acc', 'train_acc', 'test_acc_h', 'train_acc_h'])

  return pd.DataFrame(data = acc_table, index=index, columns=columns)

tab = acc_table(unb,unb_H,ru,ru_H,smt,smt_H)
tab

"""# **XG BOOST**"""

from xgboost import XGBClassifier
xgb = XGBClassifier()

"""**Dengesiz veri seti ile eğitilmesi ve sonuçlar:**"""

unb =  ml_alg(densizx_train, densizy_train, densizx_test, densizy_test, xgb, 0)
print("Dengesiz test kümesinin başarı oranı: ",unb[0])
print("Dengesiz train kümesinin başarı oranı: ",unb[1])

"""**Random Unsampling uygulanmış veri seti ile eğitim ve test:**"""

ru = ml_alg(rusx_train, rusy_train, rusx_test, rusy_test, xgb, 0)

print("Dengeli(Random Unsampling) test kümesinin başarı oranı: ",ru[0])
print("Dengeli(Random Unsampling) train kümesinin başarı oranı: ",ru[1])

"""**SMOTE uygulanmış veri seti ile eğitim ve test:**"""

smt = ml_alg(smox_train, smoy_train, smox_test, smoy_test, xgb, 0)

print("Dengeli(SMOTE) veri kümesinin başarı oranı: ",smt[0])
print("Dengeli(SMOTE) veri kümesinin başarı oranı: ",smt[1])

param_grid = {
            'n_estimators': [100, 500, 900, 1100, 1500],
            'max_depth':[2, 3, 5, 10, 15],
            'learning_rate':[0.05,0.1,0.15,0.20],
            'min_child_weight':[1,2,3,4],
            'subsample': [0.5, 1.0, 0.11],
            'eta': [0.1, 0.26, 0.05],
            'booster':['gbtree','gblinear'],
            'colsample_bytree': [0.5, 1.0, 0.11]
        }
grid_search = GridSearchCV(XGBClassifier() , param_grid = param_grid, n_jobs = -1, cv=5)

"""**Dengesiz veri seti ile grid search uygulanmış model sonuçları:**"""

unb_H = ml_alg(densizx_train, densizy_train, densizx_test, densizy_test, grid_search, 1)
print("Dengesiz test kümesi ile grid search uygulanmış modelin başarı oranı: ",unb_H[0])
print("Dengesiz train kümesi ile grid search uygulanmış modelin başarı oranı: ",unb_H[1])

"""**Random Undersampling veri seti ile grid search uygulanmış model sonuçları:**"""

ru_H = ml_alg(rusx_train, rusy_train, rusx_test, rusy_test, grid_search, 1)
print("Dengeli(Random Unsampling) test kümesi ile grid search uygulanmış modelin başarı oranı: ",ru_H[0])
print("Dengeli(Random Unsampling) train kümesi ile grid search uygulanmış modelin başarı oranı: ",ru_H[1])

"""**Smote veri seti ile grid search uygulanmış model sonuçları:**"""

smt_H = ml_alg(smox_train, smoy_train, smox_test, smoy_test, grid_search, 1)

print("Dengeli(SMOTE) kümesi ile grid search uygulanmış modelin başarı oranı: ",smt_H[0])
print("Dengeli(SMOTE) kümesi ile grid search uygulanmış modelin başarı oranı: ",smt_H[1])

tab = acc_table(unb,unb_H,ru,ru_H,smt,smt_H)
tab

"""# **KNN**"""

from sklearn.neighbors import KNeighborsClassifier
knn = KNeighborsClassifier()

"""**Dengesiz veri seti ile eğitilmesi ve sonuçlar:**"""

unb =  ml_alg(densizx_train, densizy_train, densizx_test, densizy_test, knn, 0)
print("Dengesiz test kümesinin başarı oranı: ",unb[0])
print("Dengesiz train kümesinin başarı oranı: ",unb[1])

"""**Random Unsampling uygulanmış veri seti ile eğitim ve test:**"""

ru = ml_alg(rusx_train, rusy_train, rusx_test, rusy_test, knn, 0)

print("Dengeli(Random Unsampling) test kümesinin başarı oranı: ",ru[0])
print("Dengeli(Random Unsampling) train kümesinin başarı oranı: ",ru[1])

"""**SMOTE uygulanmış veri seti ile eğitim ve test:**"""

smt = ml_alg(smox_train, smoy_train, smox_test, smoy_test, knn, 0)

print("Dengeli(SMOTE) veri kümesinin başarı oranı: ",smt[0])
print("Dengeli(SMOTE) veri kümesinin başarı oranı: ",smt[1])

param_grid = {
    'n_neighbors': range(1,100), 
    'weights': ['uniform','distance'],
    'p':[1,2,5],
    'metric':['euclidean','minkowski','mahalanobis','seuclidean'],
    }
grid_search = GridSearchCV(KNeighborsClassifier(), param_grid=param_grid, n_jobs=-1, verbose=1, cv=5)

"""**Dengesiz veri seti ile grid search uygulanmış model sonuçları:**"""

unb_H = ml_alg(densizx_train, densizy_train, densizx_test, densizy_test, grid_search, 1)
print("Dengesiz test kümesi ile grid search uygulanmış modelin başarı oranı: ",unb_H[0])
print("Dengesiz train kümesi ile grid search uygulanmış modelin başarı oranı: ",unb_H[1])

"""**Random Undersampling veri seti ile grid search uygulanmış model sonuçları:**"""

ru_H = ml_alg(rusx_train, rusy_train, rusx_test, rusy_test, grid_search, 1)
print("Dengeli(Random Unsampling) test kümesi ile grid search uygulanmış modelin başarı oranı: ",ru_H[0])
print("Dengeli(Random Unsampling) train kümesi ile grid search uygulanmış modelin başarı oranı: ",ru_H[1])

"""**Smote veri seti ile grid search uygulanmış model sonuçları:**"""

smt_H = ml_alg(smox_train, smoy_train, smox_test, smoy_test, grid_search, 1)

print("Dengeli(SMOTE) kümesi ile grid search uygulanmış modelin başarı oranı: ",smt_H[0])
print("Dengeli(SMOTE) kümesi ile grid search uygulanmış modelin başarı oranı: ",smt_H[1])

tab = acc_table(unb,unb_H,ru,ru_H,smt,smt_H)
tab

"""# **MLP**"""

from sklearn.neural_network import MLPClassifier
mlp = MLPClassifier()

"""**Dengesiz veri seti ile eğitilmesi ve sonuçlar:**"""

unb =  ml_alg(densizx_train, densizy_train, densizx_test, densizy_test, mlp, 0)
print("Dengesiz test kümesinin başarı oranı: ",unb[0])
print("Dengesiz train kümesinin başarı oranı: ",unb[1])

"""**Random Unsampling uygulanmış veri seti ile eğitim ve test:**"""

ru = ml_alg(rusx_train, rusy_train, rusx_test, rusy_test, mlp, 0)

print("Dengeli(Random Unsampling) test kümesinin başarı oranı: ",ru[0])
print("Dengeli(Random Unsampling) train kümesinin başarı oranı: ",ru[1])

"""**SMOTE uygulanmış veri seti ile eğitim ve test:**"""

smt = ml_alg(smox_train, smoy_train, smox_test, smoy_test, mlp, 0)

print("Dengeli(SMOTE) veri kümesinin başarı oranı: ",smt[0])
print("Dengeli(SMOTE) veri kümesinin başarı oranı: ",smt[1])

param_grid={
    'solver': ['adam'],
     'learning_rate_init': [0.0001],
     'max_iter': [200, 1000, 5000, 10000],
     'hidden_layer_sizes': [(150,100,50), (120,80,40), (100,50,30)],
     'activation': ['logistic', 'tanh', 'relu'],
     'alpha': [0.0001, 0.001, 0.005],
     'early_stopping': [False]
    }

grid_search = GridSearchCV(MLPClassifier(), param_grid=param_grid,  cv=5,
                            n_jobs=-1, refit=True, verbose=1, 
                            return_train_score=False)

"""**Dengesiz veri seti ile grid search uygulanmış model sonuçları:**"""

unb_H = ml_alg(densizx_train, densizy_train, densizx_test, densizy_test, grid_search, 1)
print("Dengesiz test kümesi ile grid search uygulanmış modelin başarı oranı: ",unb_H[0])
print("Dengesiz train kümesi ile grid search uygulanmış modelin başarı oranı: ",unb_H[1])

mlp = MLPClassifier(activation='tanh', hidden_layer_sizes=(100,2),learning_rate='adaptive', solver='adam', max_iter=2000)
unb_H1 = ml_alg(densizx_train, densizy_train, densizx_test, densizy_test, mlp, 0)
print(unb_H1)

"""**Random Undersampling veri seti ile grid search uygulanmış model sonuçları:**"""

ru_H = ml_alg(rusx_train, rusy_train, rusx_test, rusy_test, grid_search, 1)
print("Dengeli(Random Unsampling) test kümesi ile grid search uygulanmış modelin başarı oranı: ",ru_H[0])
print("Dengeli(Random Unsampling) train kümesi ile grid search uygulanmış modelin başarı oranı: ",ru_H[1])

"""**Smote veri seti ile grid search uygulanmış model sonuçları:**"""

smt_H = ml_alg(smox_train, smoy_train, smox_test, smoy_test, grid_search, 1)

print("Dengeli(SMOTE) kümesi ile grid search uygulanmış modelin başarı oranı: ",smt_H[0])
print("Dengeli(SMOTE) kümesi ile grid search uygulanmış modelin başarı oranı: ",smt_H[1])

tab = acc_table(unb,unb_H,ru,ru_H,smt,smt_H)
tab

model.score(smox_test, smoy_test)

model.score(smox_train, smoy_train)

from sklearn.metrics import confusion_matrix

tahmin = model.predict(smox_test)

confusion_matrix(smoy_test , tahmin)

from sklearn.model_selection import cross_val_score

scores = cross_val_score(model ,smox_df, smoy_df, cv=10)
scores.mean()

from sklearn.metrics import accuracy_score

print('Accuracy: %.4f' % accuracy_score(smoy_test,tahmin))

import sklearn.metrics as metrics

fpr , tpr , thresolds = metrics.roc_curve(smoy_test , tahmin)

roc_auc = metrics.auc(fpr , tpr)

import matplotlib.pyplot as plt

plt.plot(fpr , tpr ,'b' ,label = 'AUC =0.2f' %roc_auc)

roc_auc

"""# **Support Vector Machine**

# Dengesiz Veriseti
"""

from sklearn.svm import SVC

from sklearn.model_selection import GridSearchCV

def svc_param_selection(X , Y , nfolds):
  Cler = [0.0001,0.001,0.01,0.1,0.5,1,5,10,100,1000]
  gammalar = [0.001 , 0.01 , 0.1 , 1]
  param_grid = {"C":Cler , "gamma":gammalar  }
  grid_search = GridSearchCV(SVC() , param_grid , cv=nfolds)
  grid_search.fit(X,Y)
  return print(grid_search.best_params_)

svc_param_selection(densizx_train , densizy_train , 4)

model = SVC(random_state=1 , C=5,gamma=0.01)

model.fit(densizx_train,densizy_train)

model.score(densizx_test,densizy_test)

model.score(densizx_train,densizy_train)

from sklearn.model_selection import cross_val_score

scores = cross_val_score(model , x, y, cv=10)
scores.mean()

from sklearn.metrics import confusion_matrix

tahmin = model.predict(densizx_test)

confusion_matrix(densizy_test , tahmin)

from sklearn.metrics import accuracy_score

print('Accuracy: %.4f' % accuracy_score(densizy_test,tahmin))

import sklearn.metrics as metrics

fpr , tpr , thresolds = metrics.roc_curve(densizy_test , tahmin)

roc_auc = metrics.auc(fpr , tpr)

import matplotlib.pyplot as plt

plt.plot(fpr , tpr ,'b' ,label = 'AUC =0.2f' %roc_auc)

roc_auc

"""# Random Unsampling"""

def svc_param_selection(X , Y , nfolds):
  Cler = [0.0001,0.001,0.01,0.1,0.5,1,5,10,100,1000]
  gammalar = [0.001 , 0.01 , 0.1 , 1]
  param_grid = {"C":Cler , "gamma":gammalar  }
  grid_search = GridSearchCV(SVC() , param_grid , cv=nfolds)
  grid_search.fit(X,Y)
  return print(grid_search.best_params_)

svc_param_selection(rusx_train , rusy_train , 4)

model = SVC(random_state=1 , C=0.1,gamma=1)

model.fit(rusx_train,rusy_train)

model.score(rusx_test,rusy_test)

model.score(rusx_train,rusy_train)

from sklearn.model_selection import cross_val_score

scores = cross_val_score(model , rusx_df, rusy_df, cv=10)
scores.mean()

from sklearn.metrics import confusion_matrix

tahmin = model.predict(rusx_test)

confusion_matrix(rusy_test , tahmin)

from sklearn.metrics import accuracy_score

print('Accuracy: %.4f' % accuracy_score(rusy_test,tahmin))

import sklearn.metrics as metrics

fpr , tpr , thresolds = metrics.roc_curve(rusy_test , tahmin)

roc_auc = metrics.auc(fpr , tpr)

import matplotlib.pyplot as plt

plt.plot(fpr , tpr ,'b' ,label = 'AUC =0.2f' %roc_auc)

roc_auc

"""# SMOTE"""

from sklearn.svm import SVC

from sklearn.model_selection import GridSearchCV

def svc_param_selection(X , Y , nfolds):
  Cler = [0.0001,0.001,0.01,0.1,0.5,1,5,10,100,1000]
  gammalar = [0.001 , 0.01 , 0.1 , 1]
  param_grid = {"C":Cler , "gamma":gammalar  }
  grid_search = GridSearchCV(SVC() , param_grid , cv=nfolds)
  grid_search.fit(X,Y)
  return print(grid_search.best_params_)

svc_param_selection(smox_train , smoy_train , 4)

model = SVC(random_state=1 , C=10,gamma=1)

model.fit(smox_train,smoy_train)

model.score(smox_test,smoy_test)

model.score(smox_train,smoy_train)

from sklearn.model_selection import cross_val_score

scores = cross_val_score(model , smox_df, smoy_df, cv=10)
scores.mean()

from sklearn.metrics import confusion_matrix

tahmin = model.predict(smox_test)

confusion_matrix(smoy_test , tahmin)

from sklearn.metrics import accuracy_score

print('Accuracy: %.4f' % accuracy_score(smoy_test,tahmin))

import sklearn.metrics as metrics

fpr , tpr , thresolds = metrics.roc_curve(smoy_test , tahmin)

roc_auc = metrics.auc(fpr , tpr)

import matplotlib.pyplot as plt

plt.plot(fpr , tpr ,'b' ,label = 'AUC =0.2f' %roc_auc)

roc_auc

"""# **Random Forest**

# Dengesiz Veriseti
"""

from sklearn.ensemble import RandomForestClassifier

from sklearn.model_selection import GridSearchCV

def RandomForest_param_selection(X , Y , nfolds):
  n_estimators = [120,300,500,800,1200]
  max_depth = [5,8,15,25,30]
  min_samples_split = [1,2,5,10,15,100]
  min_samples_leaf = [1,2,5,10]
  
  param_grid = {
        "n_estimators":n_estimators ,
        "max_depth":max_depth ,
        "min_samples_split":min_samples_split ,
        "min_samples_leaf":min_samples_leaf        
            }
  grid_search = GridSearchCV(RandomForestClassifier() , param_grid , cv=nfolds)
  grid_search.fit(X,Y)
  return print(grid_search.best_params_)

RandomForest_param_selection(densizx_train , densizy_train , 4)

model = RandomForestClassifier(n_estimators=120 ,max_depth=25, min_samples_leaf=2, min_samples_split=10, random_state=42)

model.fit(densizx_train,densizy_train)

model.score(densizx_test,densizy_test)

model.score(densizx_train,densizy_train)

from sklearn.model_selection import cross_val_score

scores = cross_val_score(model , x, y, cv=10)
scores.mean()

from sklearn.metrics import confusion_matrix

tahmin = model.predict(densizx_test)

confusion_matrix(densizy_test , tahmin)

from sklearn.metrics import accuracy_score

print('Accuracy: %.4f' % accuracy_score(densizy_test,tahmin))

import sklearn.metrics as metrics

fpr , tpr , thresolds = metrics.roc_curve(densizy_test , tahmin)

roc_auc = metrics.auc(fpr , tpr)

import matplotlib.pyplot as plt

plt.plot(fpr , tpr ,'b' ,label = 'AUC =0.2f' %roc_auc)

roc_auc

"""# Random Unsampling"""

def RandomForest_param_selection(X , Y , nfolds):
  n_estimators = [120,300,500,800,1200]
  max_depth = [5,8,15,25,30]
  min_samples_split = [1,2,5,10,15,100]
  min_samples_leaf = [1,2,5,10]
  
  param_grid = {
        "n_estimators":n_estimators ,
        "max_depth":max_depth ,
        "min_samples_split":min_samples_split ,
        "min_samples_leaf":min_samples_leaf       
            }
  grid_search = GridSearchCV(RandomForestClassifier() , param_grid , cv=nfolds)
  grid_search.fit(X,Y)
  return print(grid_search.best_params_)

RandomForest_param_selection(rusx_train , rusy_train , 2)

model = RandomForestClassifier(n_estimators=120 ,max_depth=25, min_samples_leaf=2, min_samples_split=10, random_state=42)

model.fit(rusx_train,rusy_train)

model.score(rusx_test,rusy_test)

model.score(rusx_train,rusy_train)

from sklearn.model_selection import cross_val_score

scores = cross_val_score(model , rusx_df, rusy_df, cv=10)
scores.mean()

from sklearn.metrics import confusion_matrix

tahmin = model.predict(rusx_test)

confusion_matrix(rusy_test , tahmin)

from sklearn.metrics import accuracy_score

print('Accuracy: %.4f' % accuracy_score(rusy_test,tahmin))

import sklearn.metrics as metrics

fpr , tpr , thresolds = metrics.roc_curve(rusy_test , tahmin)

roc_auc = metrics.auc(fpr , tpr)

import matplotlib.pyplot as plt

plt.plot(fpr , tpr ,'b' ,label = 'AUC =0.2f' %roc_auc)

roc_auc

"""# SMOTE"""

def RandomForest_param_selection(X , Y , nfolds):
  n_estimators = [120,300,500,800,1200]
  max_depth = [5,8,15,25,30]
  min_samples_split = [1,2,5,10,15,100]
  min_samples_leaf = [1,2,5,10]
  
  param_grid = {
        "n_estimators":n_estimators ,
        "max_depth":max_depth ,
        "min_samples_split":min_samples_split ,
        "min_samples_leaf":min_samples_leaf       
            }
  grid_search = GridSearchCV(RandomForestClassifier() , param_grid , cv=nfolds)
  grid_search.fit(X,Y)
  return print(grid_search.best_params_)

RandomForest_param_selection(smox_train , smoy_train , 2)

model = RandomForestClassifier(n_estimators=120 ,max_depth=25, min_samples_leaf=2, min_samples_split=10, random_state=42)

model.fit(smox_train,smoy_train)

model.score(smox_test,smoy_test)

model.score(smox_train,smoy_train)

from sklearn.model_selection import cross_val_score

scores = cross_val_score(model ,smox_df, smoy_df, cv=10)
scores.mean()

from sklearn.metrics import confusion_matrix

tahmin = model.predict(smox_test)

confusion_matrix(smoy_test , tahmin)

from sklearn.metrics import accuracy_score

print('Accuracy: %.4f' % accuracy_score(smoy_test,tahmin))

import sklearn.metrics as metrics

fpr , tpr , thresolds = metrics.roc_curve(smoy_test , tahmin)

roc_auc = metrics.auc(fpr , tpr)

import matplotlib.pyplot as plt

plt.plot(fpr , tpr ,'b' ,label = 'AUC =0.2f' %roc_auc)

roc_auc

"""# **Desicion Tree**

# Dengesiz Veri seti
"""

from sklearn import tree
from sklearn.tree import DecisionTreeClassifier

decision_tree = DecisionTreeClassifier()
decision_tree.fit=(densizx_train,densizy_train)

model = tree.DecisionTreeClassifier()

model.fit(densizx_train, densizy_train)

param_dict = {
    "criterion":['gini','entropy'],
    "max_depth":range(1,10),
    "min_samples_split":range(1,10),
    "min_samples_leaf":range(1,5)
}

grid = GridSearchCV(decision_tree,
                     param_grid=param_dict,
                     cv=10,
                     verbose=1,
                     n_jobs=-1)
grid.fit(densizx_train,densizy_train)

grid.best_params_

grid.best_estimator_

model = DecisionTreeClassifier(criterion='gini', max_depth=3, min_samples_leaf=1,min_samples_split=2)

model.fit(densizx_train,densizy_train)

grid.best_score_

model.score(densizx_test, densizy_test)

model.score(densizx_train, densizy_train)

from sklearn.metrics import confusion_matrix

tahmin = model.predict(densizx_test)

confusion_matrix(densizy_test , tahmin)

from sklearn.model_selection import cross_val_score

scores = cross_val_score(model , x , y, cv=10)
scores.mean()

from sklearn.metrics import accuracy_score

print('Accuracy: %.4f' % accuracy_score(densizy_test,tahmin))

import sklearn.metrics as metrics

fpr , tpr , thresolds = metrics.roc_curve(densizy_test , tahmin)

roc_auc = metrics.auc(fpr , tpr)

import matplotlib.pyplot as plt

plt.plot(fpr , tpr ,'b' ,label = 'AUC =0.2f' %roc_auc)

roc_auc

"""# Random Undersampling"""

decision_tree = DecisionTreeClassifier()
decision_tree.fit=(rusx_train,rusy_train)

model = tree.DecisionTreeClassifier()

model.fit(rusx_train, rusy_train)

param_dict = {
    "criterion":['gini','entropy'],
    "max_depth":range(1,10),
    "min_samples_split":range(1,10),
    "min_samples_leaf":range(1,5)
}

grid = GridSearchCV(decision_tree,
                     param_grid=param_dict,
                     cv=10,
                     verbose=1,
                     n_jobs=-1)
grid.fit(rusx_train,rusy_train)

grid.best_params_

grid.best_estimator_

model = DecisionTreeClassifier(criterion='gini', max_depth=3, min_samples_leaf=1,min_samples_split=2)

model.fit(rusx_train,rusy_train)

grid.best_score_

model.score(rusx_test, rusy_test)

model.score(rusx_train, rusy_train)

from sklearn.metrics import confusion_matrix

tahmin = model.predict(rusx_test)

confusion_matrix(rusy_test , tahmin)

from sklearn.model_selection import cross_val_score

scores = cross_val_score(model ,rusx_df, rusy_df, cv=10)
scores.mean()

from sklearn.metrics import accuracy_score

print('Accuracy: %.4f' % accuracy_score(rusy_test,tahmin))

import sklearn.metrics as metrics

fpr , tpr , thresolds = metrics.roc_curve(rusy_test , tahmin)

roc_auc = metrics.auc(fpr , tpr)

import matplotlib.pyplot as plt

plt.plot(fpr , tpr ,'b' ,label = 'AUC =0.2f' %roc_auc)

roc_auc

"""

# SMOTE




"""

decision_tree = DecisionTreeClassifier()
decision_tree.fit=(smox_train,smoy_train)

model = tree.DecisionTreeClassifier()

model.fit(smox_train, smoy_train)

param_dict = {
    "criterion":['gini','entropy'],
    "max_depth":range(1,10),
    "min_samples_split":range(1,10),
    "min_samples_leaf":range(1,5)
}

grid = GridSearchCV(decision_tree,
                     param_grid=param_dict,
                     cv=10,
                     verbose=1,
                     n_jobs=-1)
grid.fit(smox_train,smoy_train)

grid.best_params_

grid.best_estimator_

model = DecisionTreeClassifier(criterion='gini', max_depth=3, min_samples_leaf=1,min_samples_split=2)

model.fit(smox_train,smoy_train)

grid.best_score_